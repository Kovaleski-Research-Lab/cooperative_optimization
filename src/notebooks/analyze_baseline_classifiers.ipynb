{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ffc026a-420b-493c-a602-c69ad7650234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import os\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from torchmetrics.classification import F1Score, Accuracy, Precision, Recall\n",
    "sys.path.append('../')\n",
    "from datamodule.datamodule import select_data\n",
    "from models.models import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3867e80f-55b3-4df3-83be-e5f3fa2e6404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Solarize_Light2', '_classic_test_patch', '_mpl-gallery', '_mpl-gallery-nogrid', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn-v0_8', 'seaborn-v0_8-bright', 'seaborn-v0_8-colorblind', 'seaborn-v0_8-dark', 'seaborn-v0_8-dark-palette', 'seaborn-v0_8-darkgrid', 'seaborn-v0_8-deep', 'seaborn-v0_8-muted', 'seaborn-v0_8-notebook', 'seaborn-v0_8-paper', 'seaborn-v0_8-pastel', 'seaborn-v0_8-poster', 'seaborn-v0_8-talk', 'seaborn-v0_8-ticks', 'seaborn-v0_8-white', 'seaborn-v0_8-whitegrid', 'tableau-colorblind10']\n"
     ]
    }
   ],
   "source": [
    "print(plt.style.available)\n",
    "plt.style.use('seaborn-v0_8-dark-palette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6342494d-8851-445c-837a-188ae19385c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = '../../'\n",
    "path_results = os.path.join(path_root, 'results/baseline_classifier_analysis')\n",
    "config = yaml.load(open(os.path.join(path_root, 'config.yaml')), Loader=yaml.FullLoader)\n",
    "\n",
    "os.makedirs(path_results, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf0daeaa-b3e9-4a9d-9f7f-87c1430f4efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_files = os.listdir(os.path.join(path_root, 'results'))\n",
    "result_files = [os.path.join(path_root, 'results', f) for f in result_files if 'classifier_baseline' in f]\n",
    "result_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef2091e8-b888-49f7-a1eb-accb5551baa1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m bench_image_folder \u001b[38;5;241m=\u001b[39m result_files[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m resampled_sample_folder \u001b[38;5;241m=\u001b[39m \u001b[43mresult_files\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m sim_output_folder \u001b[38;5;241m=\u001b[39m result_files[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "bench_image_folder = result_files[0]\n",
    "resampled_sample_folder = result_files[1]\n",
    "sim_output_folder = result_files[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145813fb-42d2-429d-aa16-d11ef640599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_image_versions = os.listdir(bench_image_folder)\n",
    "bench_image_versions = [i for i in bench_image_versions if '.ipynb' not in i]\n",
    "\n",
    "resampled_sample_versions = os.listdir(resampled_sample_folder)\n",
    "resampled_sample_versions = [i for i in resampled_sample_versions if '.ipynb' not in i]\n",
    "\n",
    "sim_output_versions = os.listdir(sim_output_folder)\n",
    "sim_output_versions = [i for i in sim_output_versions if '.ipynb' not in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3f07f-a316-4ea0-ae3a-22258c6de736",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sim_output_versions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9faab19-96a0-4c1a-b37b-f961852f2653",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279c881f-2c5a-460b-8941-b27b2157e85f",
   "metadata": {},
   "source": [
    "## Bench image version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab92adb4-ab6b-44b8-b81b-9f8de960cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the metrics\n",
    "version_metrics = {}\n",
    "for version in bench_image_versions:\n",
    "    metrics = {}\n",
    "    path_metrics = os.path.join(bench_image_folder, version, 'logs', 'metrics.csv')\n",
    "    try:\n",
    "        with open(path_metrics) as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=',')\n",
    "            for i,row in enumerate(reader):\n",
    "                if i == 0:\n",
    "                    for header in row:\n",
    "                        metrics[header] = []\n",
    "                    key_list = list(metrics.keys())\n",
    "                else:\n",
    "                    for j,value in enumerate(row):\n",
    "                        metrics[key_list[j]].append(value)\n",
    "        version_metrics[version] = metrics\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8897d8-2464-451a-a80e-346c6aad1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the metrics\n",
    "for k,metrics in version_metrics.items():\n",
    "    metrics['epoch'] = np.unique(np.asarray(metrics['epoch'], dtype=int))\n",
    "    metrics['loss_train'] = np.asarray([float(i) for i in metrics['loss_train'] if i != ''])\n",
    "    metrics['loss_val'] = np.asarray([float(i) for i in metrics['loss_val'] if i != ''])\n",
    "    version_metrics[k] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06199f87-e849-4c92-90d7-8080c1902a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a tag for either pretrained or not from the version config\n",
    "bench_image_version_tags = {}\n",
    "for version in bench_image_versions:\n",
    "    config = yaml.load(open(os.path.join(bench_image_folder, version, 'config.yaml'), 'r'), Loader = yaml.FullLoader)\n",
    "    if config['classifier']['transfer_learn']:\n",
    "        bench_image_version_tags[version] = 'pretrained'\n",
    "    else:\n",
    "        bench_image_version_tags[version] = 'non-pretrained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95c9f39-4570-4890-a9b3-63bbe6b7e1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss\n",
    "fig , ax = plt.subplots(2,1, figsize=(5,5))\n",
    "\n",
    "for version in bench_image_versions:\n",
    "    if bench_image_version_tags[version] == 'pretrained':\n",
    "        ax[0].plot(version_metrics[version]['epoch'], version_metrics[version]['loss_train'], label='Pretrained')\n",
    "        ax[1].plot(version_metrics[version]['epoch'], version_metrics[version]['loss_val'], label = 'Pretrained')\n",
    "    elif bench_image_version_tags[version] == 'non-pretrained':\n",
    "        ax[0].plot(version_metrics[version]['epoch'], version_metrics[version]['loss_train'], label='Non pretrained')\n",
    "        ax[1].plot(version_metrics[version]['epoch'], version_metrics[version]['loss_val'], label='Non pretrained')\n",
    "\n",
    "ax[0].set_title(\"Train loss\")\n",
    "ax[1].set_title(\"Validation loss\")\n",
    "ax[0].legend(loc='upper right')\n",
    "ax[1].legend(loc='upper right')\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.set_xlabel(\"Epoch\")\n",
    "    a.set_ylabel(\"Cross Entropy Loss\")\n",
    "    a.set_xticks([i for i in range(0,21,2)], [i for i in range(0,21,2)])\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(path_results, 'bench_images_loss.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1dba1e-db3d-4d63-8531-bbb38c8071c0",
   "metadata": {},
   "source": [
    "## Resampled sample version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98326b7-8fc4-48e2-9741-86b304916945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the metrics\n",
    "version_metrics = {}\n",
    "for version in resampled_sample_versions:\n",
    "    metrics = {}\n",
    "    path_metrics = os.path.join(resampled_sample_folder, version, 'logs', 'metrics.csv')\n",
    "    try:\n",
    "        with open(path_metrics) as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=',')\n",
    "            for i,row in enumerate(reader):\n",
    "                if i == 0:\n",
    "                    for header in row:\n",
    "                        metrics[header] = []\n",
    "                    key_list = list(metrics.keys())\n",
    "                else:\n",
    "                    for j,value in enumerate(row):\n",
    "                        metrics[key_list[j]].append(value)\n",
    "        version_metrics[version] = metrics\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a75c29-10d2-409f-ab37-12b722c0a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the metrics\n",
    "for k,metrics in version_metrics.items():\n",
    "    metrics['epoch'] = np.unique(np.asarray(metrics['epoch'], dtype=int))\n",
    "    metrics['loss_train'] = np.asarray([float(i) for i in metrics['loss_train'] if i != ''])\n",
    "    metrics['loss_val'] = np.asarray([float(i) for i in metrics['loss_val'] if i != ''])\n",
    "    version_metrics[k] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09adf378-bbaa-4280-8826-315376549526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a tag for either pretrained or not from the version config\n",
    "resampled_sample_version_tags = {}\n",
    "for version in resampled_sample_versions:\n",
    "    config = yaml.load(open(os.path.join(resampled_sample_folder, version, 'config.yaml'), 'r'), Loader = yaml.FullLoader)\n",
    "    if config['classifier']['transfer_learn']:\n",
    "        resampled_sample_version_tags[version] = 'pretrained'\n",
    "    else:\n",
    "        resampled_sample_version_tags[version] = 'non-pretrained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660f28e5-2498-4500-9a77-09167cf566e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss\n",
    "fig , ax = plt.subplots(2,1, figsize=(5,5))\n",
    "\n",
    "for version in resampled_sample_versions:\n",
    "    if resampled_sample_version_tags[version] == 'pretrained':\n",
    "        ax[0].plot(version_metrics[version]['epoch'], version_metrics[version]['loss_train'], label='Pretrained')\n",
    "        ax[1].plot(version_metrics[version]['epoch'], version_metrics[version]['loss_val'], label = 'Pretrained')\n",
    "    elif resampled_sample_version_tags[version] == 'non-pretrained':\n",
    "        ax[0].plot(version_metrics[version]['epoch'], version_metrics[version]['loss_train'], label='Non pretrained')\n",
    "        ax[1].plot(version_metrics[version]['epoch'], version_metrics[version]['loss_val'], label='Non pretrained')\n",
    "\n",
    "ax[0].set_title(\"Train loss\")\n",
    "ax[1].set_title(\"Validation loss\")\n",
    "ax[0].legend(loc='upper right')\n",
    "ax[1].legend(loc='upper right')\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.set_xlabel(\"Epoch\")\n",
    "    a.set_ylabel(\"Cross Entropy Loss\")\n",
    "    a.set_xticks([i for i in range(0,21,2)], [i for i in range(0,21,2)])\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(path_results, 'resampled_sample_loss.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9391e940-1294-491d-9d53-70709936e5bb",
   "metadata": {},
   "source": [
    "## Sim output version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6c6b68-ec9f-4b6e-9407-ca0454036871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the metrics\n",
    "version_metrics = {}\n",
    "for version in sim_output_versions:\n",
    "    metrics = {}\n",
    "    path_metrics = os.path.join(sim_output_folder, version, 'logs', 'metrics.csv')\n",
    "    try:\n",
    "        with open(path_metrics) as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=',')\n",
    "            for i,row in enumerate(reader):\n",
    "                if i == 0:\n",
    "                    for header in row:\n",
    "                        metrics[header] = []\n",
    "                    key_list = list(metrics.keys())\n",
    "                else:\n",
    "                    for j,value in enumerate(row):\n",
    "                        metrics[key_list[j]].append(value)\n",
    "        version_metrics[version] = metrics\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce082118-20c2-44e1-b1d9-f41d22be3286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the metrics\n",
    "for k,metrics in version_metrics.items():\n",
    "    metrics['epoch'] = np.unique(np.asarray(metrics['epoch'], dtype=int))\n",
    "    metrics['loss_train'] = np.asarray([float(i) for i in metrics['loss_train'] if i != ''])\n",
    "    metrics['loss_val'] = np.asarray([float(i) for i in metrics['loss_val'] if i != ''])\n",
    "    version_metrics[k] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb63088-ea11-4aa0-ba93-8b1b1bce7894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a tag for either pretrained or not from the version config\n",
    "sim_output_version_tags = {}\n",
    "for version in sim_output_versions:\n",
    "    config = yaml.load(open(os.path.join(sim_output_folder, version, 'config.yaml'), 'r'), Loader = yaml.FullLoader)\n",
    "    if config['classifier']['transfer_learn']:\n",
    "        sim_output_version_tags[version] = 'pretrained'\n",
    "    else:\n",
    "        sim_output_version_tags[version] = 'non-pretrained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad02a3-f59b-4855-9437-0ebdc80660ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss\n",
    "fig , ax = plt.subplots(2,1, figsize=(5,5))\n",
    "\n",
    "for version in sim_output_versions:\n",
    "    if sim_output_version_tags[version] == 'pretrained':\n",
    "        ax[0].plot(version_metrics[version]['epoch'], version_metrics[version]['loss_train'], label='Pretrained')\n",
    "        ax[1].plot(version_metrics[version]['epoch'], version_metrics[version]['loss_val'], label = 'Pretrained')\n",
    "    elif sim_output_version_tags[version] == 'non-pretrained':\n",
    "        ax[0].plot(version_metrics[version]['epoch'], version_metrics[version]['loss_train'], label='Non pretrained')\n",
    "        ax[1].plot(version_metrics[version]['epoch'], version_metrics[version]['loss_val'], label='Non pretrained')\n",
    "\n",
    "ax[0].set_title(\"Train loss\")\n",
    "ax[1].set_title(\"Validation loss\")\n",
    "ax[0].legend(loc='upper right')\n",
    "ax[1].legend(loc='upper right')\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.set_xlabel(\"Epoch\")\n",
    "    a.set_ylabel(\"Cross Entropy Loss\")\n",
    "    a.set_xticks([i for i in range(0,21,2)], [i for i in range(0,21,2)])\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(path_results, 'sim_output_loss.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a85368d-cbaa-481a-aca6-b6bda2b3ecb0",
   "metadata": {},
   "source": [
    "# Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf954d2-4fdd-44aa-96d2-8eab4144a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_image_preds = {}\n",
    "sim_output_preds = {}\n",
    "resampled_sample_preds = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3177c3-73d9-4ba8-8d9b-499b37ade221",
   "metadata": {},
   "source": [
    "## Bench images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b751411-34c5-42f3-8e7f-906fabb016a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_image_preds['bench_image'] = {}\n",
    "sim_output_preds['bench_image'] = {}\n",
    "resampled_sample_preds['bench_image'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6bc881-507e-4a8d-8ac6-0f20514362c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config['which_data'] = 'bench_image'\n",
    "dm = select_data(config)\n",
    "dm.setup()\n",
    "train_dataloader = dm.train_dataloader()\n",
    "valid_dataloader = dm.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03218d63-2ff9-41d1-a502-882f03aa8a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_image_preds['bench_image'] = {}\n",
    "sim_output_preds['bench_image'] = {}\n",
    "resampled_sample_preds['bench_image'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0819d636-0497-4381-a5ef-51c5c044d969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for version in bench_image_versions:\n",
    "    checkpoint_path = os.path.join(bench_image_folder, version, 'checkpoints', 'last.ckpt')\n",
    "    classifier = Classifier.load_from_checkpoint(checkpoint_path).cuda()\n",
    "    bench_image_preds['bench_image'][bench_image_version_tags[version]] = {}\n",
    "    \n",
    "    bench_image_preds['bench_image'][bench_image_version_tags[version]]['train'] = {}\n",
    "    bench_image_preds['bench_image'][bench_image_version_tags[version]]['valid'] = {}\n",
    "\n",
    "    # Training dataset\n",
    "    bench_image_preds['bench_image'][bench_image_version_tags[version]]['train']['pred'] = []\n",
    "    bench_image_preds['bench_image'][bench_image_version_tags[version]]['train']['truth'] = []\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        sample, target = batch\n",
    "        \n",
    "        sample = torch.cat((sample, sample, sample), dim=1).cuda()\n",
    "        pred = classifier(sample)\n",
    "        target = torch.argmax(target, dim=-1).detach().cpu()\n",
    "        pred = torch.argmax(pred, dim=-1).cpu()\n",
    "\n",
    "        bench_image_preds['bench_image'][bench_image_version_tags[version]]['train']['pred'].append(pred)\n",
    "        bench_image_preds['bench_image'][bench_image_version_tags[version]]['train']['truth'].append(target)\n",
    "    # Validation dataset\n",
    "    bench_image_preds['bench_image'][bench_image_version_tags[version]]['valid']['pred'] = []\n",
    "    bench_image_preds['bench_image'][bench_image_version_tags[version]]['valid']['truth'] = []\n",
    "    for batch in tqdm(valid_dataloader):\n",
    "        sample, target = batch\n",
    "        \n",
    "        sample = torch.cat((sample, sample, sample), dim=1).cuda()\n",
    "        pred = classifier(sample)\n",
    "        target = torch.argmax(target, dim=-1).detach().cpu()\n",
    "        pred = torch.argmax(pred, dim=-1).cpu()\n",
    "\n",
    "        bench_image_preds['bench_image'][bench_image_version_tags[version]]['valid']['pred'].append(pred)\n",
    "        bench_image_preds['bench_image'][bench_image_version_tags[version]]['valid']['truth'].append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a72b9-d914-4361-908b-b0f3ed4111c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in bench_image_versions:\n",
    "    bench_image_preds['bench_image'][bench_image_version_tags[version]]['train']['pred'] = torch.tensor(bench_image_preds['bench_image'][bench_image_version_tags[version]]['train']['pred']).squeeze()\n",
    "    bench_image_preds['bench_image'][bench_image_version_tags[version]]['train']['truth'] = torch.tensor(bench_image_preds['bench_image'][bench_image_version_tags[version]]['train']['truth']).squeeze()\n",
    "    bench_image_preds['bench_image'][bench_image_version_tags[version]]['valid']['truth'] = torch.tensor(bench_image_preds['bench_image'][bench_image_version_tags[version]]['valid']['truth']).squeeze()\n",
    "    bench_image_preds['bench_image'][bench_image_version_tags[version]]['valid']['pred'] = torch.tensor(bench_image_preds['bench_image'][bench_image_version_tags[version]]['valid']['pred']).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff018848-c17d-4ca6-95ad-eff337b94641",
   "metadata": {},
   "outputs": [],
   "source": [
    "confmat = ConfusionMatrix(task=\"multiclass\", num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c2c5c7-e2ed-49fb-bc04-6a9862c37693",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bench_image_version_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c1e00-b477-45c0-9be0-53b819c1684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_bench_bench_train_cfm = confmat(bench_image_preds['bench_image'][bench_image_version_tags['version_0']]['train']['pred'], bench_image_preds['bench_image'][bench_image_version_tags['version_0']]['train']['truth'])\n",
    "pt_bench_bench_val_cfm = confmat(bench_image_preds['bench_image'][bench_image_version_tags['version_0']]['valid']['pred'], bench_image_preds['bench_image'][bench_image_version_tags['version_0']]['valid']['truth'])\n",
    "npt_bench_bench_train_cfm = confmat(bench_image_preds['bench_image'][bench_image_version_tags['version_1']]['train']['pred'], bench_image_preds['bench_image'][bench_image_version_tags['version_1']]['train']['truth'])\n",
    "pnt_bench_bench_val_cfm = confmat(bench_image_preds['bench_image'][bench_image_version_tags['version_1']]['valid']['pred'], bench_image_preds['bench_image'][bench_image_version_tags['version_1']]['valid']['truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e9972-3643-40ba-abbb-839c66e18251",
   "metadata": {},
   "outputs": [],
   "source": [
    "npt_bench_bench_train_cfm_df = pd.DataFrame(npt_bench_bench_train_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "npt_bench_bench_val_cfm_df = pd.DataFrame(npt_bench_bench_val_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "pt_bench_bench_train_cfm_df = pd.DataFrame(pt_bench_bench_train_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "pt_bench_bench_val_cfm_df = pd.DataFrame(pt_bench_bench_val_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff408970-f57b-433f-985e-99444e1c4d6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(10,10))\n",
    "sns.heatmap(npt_bench_bench_train_cfm_df, annot=True, ax=ax[0][0], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(npt_bench_bench_val_cfm_df, annot=True, ax=ax[1][0], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(pt_bench_bench_train_cfm_df, annot=True, ax=ax[0][1], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(pt_bench_bench_val_cfm_df, annot=True, ax=ax[1][1], square=True, cbar=False, cmap='Blues')\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.set_ylabel(\"Truth\")\n",
    "    a.set_xlabel(\"Prediction\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(path_results, 'bench_bench_cfm.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acc7d05-76a5-4ece-b54b-b3e0029a0449",
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in sim_output_versions:\n",
    "    checkpoint_path = os.path.join(sim_output_folder, version, 'checkpoints', 'last.ckpt')\n",
    "    classifier = Classifier.load_from_checkpoint(checkpoint_path).cuda()\n",
    "    sim_output_preds['bench_image'][sim_output_version_tags[version]] = {}\n",
    "    \n",
    "    sim_output_preds['bench_image'][sim_output_version_tags[version]]['train'] = {}\n",
    "    sim_output_preds['bench_image'][sim_output_version_tags[version]]['valid'] = {}\n",
    "\n",
    "    # Training dataset\n",
    "    sim_output_preds['bench_image'][sim_output_version_tags[version]]['train']['pred'] = []\n",
    "    sim_output_preds['bench_image'][sim_output_version_tags[version]]['train']['truth'] = []\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        sample, target = batch\n",
    "        \n",
    "        sample = torch.cat((sample, sample, sample), dim=1).cuda()\n",
    "        pred = classifier(sample)\n",
    "        target = torch.argmax(target, dim=-1).detach().cpu()\n",
    "        pred = torch.argmax(pred, dim=-1).cpu()\n",
    "\n",
    "        sim_output_preds['bench_image'][sim_output_version_tags[version]]['train']['pred'].append(pred)\n",
    "        sim_output_preds['bench_image'][sim_output_version_tags[version]]['train']['truth'].append(target)\n",
    "    # Validation dataset\n",
    "    sim_output_preds['bench_image'][sim_output_version_tags[version]]['valid']['pred'] = []\n",
    "    sim_output_preds['bench_image'][sim_output_version_tags[version]]['valid']['truth'] = []\n",
    "    for batch in tqdm(valid_dataloader):\n",
    "        sample, target = batch\n",
    "        \n",
    "        sample = torch.cat((sample, sample, sample), dim=1).cuda()\n",
    "        pred = classifier(sample)\n",
    "        target = torch.argmax(target, dim=-1).detach().cpu()\n",
    "        pred = torch.argmax(pred, dim=-1).cpu()\n",
    "\n",
    "        sim_output_preds['bench_image'][sim_output_version_tags[version]]['valid']['pred'].append(pred)\n",
    "        sim_output_preds['bench_image'][sim_output_version_tags[version]]['valid']['truth'].append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8c9f35-0664-441b-b134-5121bb4dcaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in sim_output_versions:\n",
    "    sim_output_preds['bench_image'][sim_output_version_tags[version]]['train']['pred'] = torch.tensor(sim_output_preds['bench_image'][sim_output_version_tags[version]]['train']['pred']).squeeze()\n",
    "    sim_output_preds['bench_image'][sim_output_version_tags[version]]['train']['truth'] = torch.tensor(sim_output_preds['bench_image'][sim_output_version_tags[version]]['train']['truth']).squeeze()\n",
    "    sim_output_preds['bench_image'][sim_output_version_tags[version]]['valid']['truth'] = torch.tensor(sim_output_preds['bench_image'][sim_output_version_tags[version]]['valid']['truth']).squeeze()\n",
    "    sim_output_preds['bench_image'][sim_output_version_tags[version]]['valid']['pred'] = torch.tensor(sim_output_preds['bench_image'][sim_output_version_tags[version]]['valid']['pred']).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dbf25c-975e-41a2-900c-4521d72bc5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sim_output_version_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4368b2f0-33ec-45b7-bc10-3f1b3485cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_sim_bench_train_cfm = confmat(sim_output_preds['bench_image'][sim_output_version_tags['version_0']]['train']['pred'], sim_output_preds['bench_image'][sim_output_version_tags['version_0']]['train']['truth'])\n",
    "pt_sim_bench_val_cfm = confmat(sim_output_preds['bench_image'][sim_output_version_tags['version_0']]['valid']['pred'], sim_output_preds['bench_image'][sim_output_version_tags['version_0']]['valid']['truth'])\n",
    "npt_sim_bench_train_cfm = confmat(sim_output_preds['bench_image'][sim_output_version_tags['version_1']]['train']['pred'], sim_output_preds['bench_image'][sim_output_version_tags['version_1']]['train']['truth'])\n",
    "npt_sim_bench_val_cfm = confmat(sim_output_preds['bench_image'][sim_output_version_tags['version_1']]['valid']['pred'], sim_output_preds['bench_image'][sim_output_version_tags['version_1']]['valid']['truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a71cc8a-6032-41eb-a1b6-0c66bc13bc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "npt_sim_bench_train_cfm_df = pd.DataFrame(npt_sim_bench_train_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "npt_sim_bench_val_cfm_df = pd.DataFrame(npt_sim_bench_val_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "pt_sim_bench_train_cfm_df = pd.DataFrame(pt_sim_bench_train_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "pt_sim_bench_val_cfm_df = pd.DataFrame(pt_sim_bench_val_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413cc55a-588d-4f85-ad2e-1aaa91a5f45c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(10,10))\n",
    "sns.heatmap(npt_sim_bench_train_cfm_df, annot=True, ax=ax[0][0], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(npt_sim_bench_val_cfm_df, annot=True, ax=ax[1][0], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(pt_sim_bench_train_cfm_df, annot=True, ax=ax[0][1], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(pt_sim_bench_val_cfm_df, annot=True, ax=ax[1][1], square=True, cbar=False, cmap='Blues')\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.set_ylabel(\"Truth\")\n",
    "    a.set_xlabel(\"Prediction\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(path_results, 'sim_bench_cfm.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d25051-7098-4873-b6ac-7b3b5f18555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in resampled_sample_versions:\n",
    "    checkpoint_path = os.path.join(resampled_sample_folder, version, 'checkpoints', 'last.ckpt')\n",
    "    classifier = Classifier.load_from_checkpoint(checkpoint_path).cuda()\n",
    "    resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]] = {}\n",
    "    \n",
    "    resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]]['train'] = {}\n",
    "    resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]]['valid'] = {}\n",
    "\n",
    "    # Training dataset\n",
    "    resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]]['train']['pred'] = []\n",
    "    resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]]['train']['truth'] = []\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        sample, target = batch\n",
    "        \n",
    "        sample = torch.cat((sample, sample, sample), dim=1).cuda()\n",
    "        pred = classifier(sample)\n",
    "        target = torch.argmax(target, dim=-1).detach().cpu()\n",
    "        pred = torch.argmax(pred, dim=-1).cpu()\n",
    "\n",
    "        resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]]['train']['pred'].append(pred)\n",
    "        resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]]['train']['truth'].append(target)\n",
    "    # Validation dataset\n",
    "    resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]]['valid']['pred'] = []\n",
    "    resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]]['valid']['truth'] = []\n",
    "    for batch in tqdm(valid_dataloader):\n",
    "        sample, target = batch\n",
    "        \n",
    "        sample = torch.cat((sample, sample, sample), dim=1).cuda()\n",
    "        pred = classifier(sample)\n",
    "        target = torch.argmax(target, dim=-1).detach().cpu()\n",
    "        pred = torch.argmax(pred, dim=-1).cpu()\n",
    "\n",
    "        resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]]['valid']['pred'].append(pred)\n",
    "        resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]]['valid']['truth'].append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5537bb48-dc41-49f5-ae63-e55667aa9ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in resampled_sample_versions:\n",
    "    resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]]['train']['pred'] = torch.tensor(resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]]['train']['pred']).squeeze()\n",
    "    resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]]['train']['truth'] = torch.tensor(resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]]['train']['truth']).squeeze()\n",
    "    resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]]['valid']['truth'] = torch.tensor(resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]]['valid']['truth']).squeeze()\n",
    "    resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]]['valid']['pred'] = torch.tensor(resampled_sample_preds['bench_image'][resampled_sample_version_tags[version]]['valid']['pred']).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c01c81d-7514-4f77-9600-d6b7c0206247",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resampled_sample_version_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e636d-568e-4f64-a74d-edfdabc2dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_sample_bench_train_cfm = confmat(resampled_sample_preds['bench_image'][resampled_sample_version_tags['version_0']]['train']['pred'], resampled_sample_preds['bench_image'][resampled_sample_version_tags['version_0']]['train']['truth'])\n",
    "pt_sample_bench_val_cfm = confmat(resampled_sample_preds['bench_image'][resampled_sample_version_tags['version_0']]['valid']['pred'], resampled_sample_preds['bench_image'][resampled_sample_version_tags['version_0']]['valid']['truth'])\n",
    "npt_sample_bench_train_cfm = confmat(resampled_sample_preds['bench_image'][resampled_sample_version_tags['version_1']]['train']['pred'], resampled_sample_preds['bench_image'][resampled_sample_version_tags['version_1']]['train']['truth'])\n",
    "npt_sample_bench_val_cfm = confmat(resampled_sample_preds['bench_image'][resampled_sample_version_tags['version_1']]['valid']['pred'], resampled_sample_preds['bench_image'][resampled_sample_version_tags['version_1']]['valid']['truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7a269d-afd9-451e-b4db-850b69fbd2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "npt_sample_bench_train_cfm_df = pd.DataFrame(npt_sample_bench_train_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "npt_sample_bench_val_cfm_df = pd.DataFrame(npt_sample_bench_val_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "pt_sample_bench_train_cfm_df = pd.DataFrame(pt_sample_bench_train_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "pt_sample_bench_val_cfm_df = pd.DataFrame(pt_sample_bench_val_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738de051-376c-468b-96eb-fe0e39a803b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(10,10))\n",
    "sns.heatmap(npt_sample_bench_train_cfm_df, annot=True, ax=ax[0][0], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(npt_sample_bench_val_cfm_df, annot=True, ax=ax[1][0], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(pt_sample_bench_train_cfm_df, annot=True, ax=ax[0][1], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(pt_sample_bench_val_cfm_df, annot=True, ax=ax[1][1], square=True, cbar=False, cmap='Blues')\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.set_ylabel(\"Truth\")\n",
    "    a.set_xlabel(\"Prediction\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(path_results, 'sample_bench_cfm.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e1978c-9d10-4cb2-8b67-83faf87c9617",
   "metadata": {},
   "source": [
    "## Simulation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6928dcb7-7ae1-4f30-bc8d-4574e6645ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_image_preds['sim_output'] = {}\n",
    "sim_output_preds['sim_output'] = {}\n",
    "resampled_sample_preds['sim_output'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c4b798-a16a-44b3-adc0-18b1dfd5b91c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config['which_data'] = 'sim_output'\n",
    "dm = select_data(config)\n",
    "dm.setup()\n",
    "train_dataloader = dm.train_dataloader()\n",
    "valid_dataloader = dm.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce5a93-0c11-4dd0-bd9f-abd443ce2007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for version in bench_image_versions:\n",
    "    checkpoint_path = os.path.join(bench_image_folder, version, 'checkpoints', 'last.ckpt')\n",
    "    classifier = Classifier.load_from_checkpoint(checkpoint_path).cuda()\n",
    "    bench_image_preds['sim_output'][bench_image_version_tags[version]] = {}\n",
    "    \n",
    "    bench_image_preds['sim_output'][bench_image_version_tags[version]]['train'] = {}\n",
    "    bench_image_preds['sim_output'][bench_image_version_tags[version]]['valid'] = {}\n",
    "\n",
    "    # Training dataset\n",
    "    bench_image_preds['sim_output'][bench_image_version_tags[version]]['train']['pred'] = []\n",
    "    bench_image_preds['sim_output'][bench_image_version_tags[version]]['train']['truth'] = []\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        sample, target = batch\n",
    "        \n",
    "        sample = torch.cat((sample, sample, sample), dim=1).cuda()\n",
    "        pred = classifier(sample)\n",
    "        target = torch.argmax(target, dim=-1).detach().cpu()\n",
    "        pred = torch.argmax(pred, dim=-1).cpu()\n",
    "\n",
    "        bench_image_preds['sim_output'][bench_image_version_tags[version]]['train']['pred'].append(pred)\n",
    "        bench_image_preds['sim_output'][bench_image_version_tags[version]]['train']['truth'].append(target)\n",
    "    # Validation dataset\n",
    "    bench_image_preds['sim_output'][bench_image_version_tags[version]]['valid']['pred'] = []\n",
    "    bench_image_preds['sim_output'][bench_image_version_tags[version]]['valid']['truth'] = []\n",
    "    for batch in tqdm(valid_dataloader):\n",
    "        sample, target = batch\n",
    "        \n",
    "        sample = torch.cat((sample, sample, sample), dim=1).cuda()\n",
    "        pred = classifier(sample)\n",
    "        target = torch.argmax(target, dim=-1).detach().cpu()\n",
    "        pred = torch.argmax(pred, dim=-1).cpu()\n",
    "\n",
    "        bench_image_preds['sim_output'][bench_image_version_tags[version]]['valid']['pred'].append(pred)\n",
    "        bench_image_preds['sim_output'][bench_image_version_tags[version]]['valid']['truth'].append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d67ed8c-1f83-4940-b2bb-2ff6738eb49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in bench_image_versions:\n",
    "    bench_image_preds['sim_output'][bench_image_version_tags[version]]['train']['pred'] = torch.tensor(bench_image_preds['sim_output'][bench_image_version_tags[version]]['train']['pred']).squeeze()\n",
    "    bench_image_preds['sim_output'][bench_image_version_tags[version]]['train']['truth'] = torch.tensor(bench_image_preds['sim_output'][bench_image_version_tags[version]]['train']['truth']).squeeze()\n",
    "    bench_image_preds['sim_output'][bench_image_version_tags[version]]['valid']['truth'] = torch.tensor(bench_image_preds['sim_output'][bench_image_version_tags[version]]['valid']['truth']).squeeze()\n",
    "    bench_image_preds['sim_output'][bench_image_version_tags[version]]['valid']['pred'] = torch.tensor(bench_image_preds['sim_output'][bench_image_version_tags[version]]['valid']['pred']).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6667548-f765-45ea-881d-787f0809d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "confmat = ConfusionMatrix(task=\"multiclass\", num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9653d0-8bf0-48b3-94f2-288a544d2d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bench_image_version_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7aba16-0734-4f2f-8365-b3a794039d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_bench_sim_train_cfm = confmat(bench_image_preds['sim_output'][bench_image_version_tags['version_0']]['train']['pred'], bench_image_preds['sim_output'][bench_image_version_tags['version_0']]['train']['truth'])\n",
    "pt_bench_sim_val_cfm = confmat(bench_image_preds['sim_output'][bench_image_version_tags['version_0']]['valid']['pred'], bench_image_preds['sim_output'][bench_image_version_tags['version_0']]['valid']['truth'])\n",
    "npt_bench_sim_train_cfm = confmat(bench_image_preds['sim_output'][bench_image_version_tags['version_1']]['train']['pred'], bench_image_preds['sim_output'][bench_image_version_tags['version_1']]['train']['truth'])\n",
    "npt_bench_sim_val_cfm = confmat(bench_image_preds['sim_output'][bench_image_version_tags['version_1']]['valid']['pred'], bench_image_preds['sim_output'][bench_image_version_tags['version_1']]['valid']['truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa758f-8a3c-4d95-95ed-da77074cfdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "npt_bench_sim_train_cfm_df = pd.DataFrame(npt_bench_sim_train_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "npt_bench_sim_val_cfm_df = pd.DataFrame(npt_bench_sim_val_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "pt_bench_sim_train_cfm_df = pd.DataFrame(pt_bench_sim_train_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "pt_bench_sim_val_cfm_df = pd.DataFrame(pt_bench_sim_val_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b468927c-411c-4138-8cfc-907f25930e01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(10,10))\n",
    "sns.heatmap(npt_bench_sim_train_cfm_df, annot=True, ax=ax[0][0], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(npt_bench_sim_val_cfm_df, annot=True, ax=ax[1][0], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(pt_bench_sim_train_cfm_df, annot=True, ax=ax[0][1], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(pt_bench_sim_val_cfm_df, annot=True, ax=ax[1][1], square=True, cbar=False, cmap='Blues')\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.set_ylabel(\"Truth\")\n",
    "    a.set_xlabel(\"Prediction\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(path_results, 'bench_sim_cfm.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5252438-b52b-449a-856c-1bfcba62494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in sim_output_versions:\n",
    "    checkpoint_path = os.path.join(sim_output_folder, version, 'checkpoints', 'last.ckpt')\n",
    "    classifier = Classifier.load_from_checkpoint(checkpoint_path).cuda()\n",
    "    sim_output_preds['sim_output'][sim_output_version_tags[version]] = {}\n",
    "    \n",
    "    sim_output_preds['sim_output'][sim_output_version_tags[version]]['train'] = {}\n",
    "    sim_output_preds['sim_output'][sim_output_version_tags[version]]['valid'] = {}\n",
    "\n",
    "    # Training dataset\n",
    "    sim_output_preds['sim_output'][sim_output_version_tags[version]]['train']['pred'] = []\n",
    "    sim_output_preds['sim_output'][sim_output_version_tags[version]]['train']['truth'] = []\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        sample, target = batch\n",
    "        \n",
    "        sample = torch.cat((sample, sample, sample), dim=1).cuda()\n",
    "        pred = classifier(sample)\n",
    "        target = torch.argmax(target, dim=-1).detach().cpu()\n",
    "        pred = torch.argmax(pred, dim=-1).cpu()\n",
    "\n",
    "        sim_output_preds['sim_output'][sim_output_version_tags[version]]['train']['pred'].append(pred)\n",
    "        sim_output_preds['sim_output'][sim_output_version_tags[version]]['train']['truth'].append(target)\n",
    "    # Validation dataset\n",
    "    sim_output_preds['sim_output'][sim_output_version_tags[version]]['valid']['pred'] = []\n",
    "    sim_output_preds['sim_output'][sim_output_version_tags[version]]['valid']['truth'] = []\n",
    "    for batch in tqdm(valid_dataloader):\n",
    "        sample, target = batch\n",
    "        \n",
    "        sample = torch.cat((sample, sample, sample), dim=1).cuda()\n",
    "        pred = classifier(sample)\n",
    "        target = torch.argmax(target, dim=-1).detach().cpu()\n",
    "        pred = torch.argmax(pred, dim=-1).cpu()\n",
    "\n",
    "        sim_output_preds['sim_output'][sim_output_version_tags[version]]['valid']['pred'].append(pred)\n",
    "        sim_output_preds['sim_output'][sim_output_version_tags[version]]['valid']['truth'].append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1985b3de-5817-40d6-81dc-ca8580ddd359",
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in sim_output_versions:\n",
    "    sim_output_preds['sim_output'][sim_output_version_tags[version]]['train']['pred'] = torch.tensor(sim_output_preds['sim_output'][sim_output_version_tags[version]]['train']['pred']).squeeze()\n",
    "    sim_output_preds['sim_output'][sim_output_version_tags[version]]['train']['truth'] = torch.tensor(sim_output_preds['sim_output'][sim_output_version_tags[version]]['train']['truth']).squeeze()\n",
    "    sim_output_preds['sim_output'][sim_output_version_tags[version]]['valid']['truth'] = torch.tensor(sim_output_preds['sim_output'][sim_output_version_tags[version]]['valid']['truth']).squeeze()\n",
    "    sim_output_preds['sim_output'][sim_output_version_tags[version]]['valid']['pred'] = torch.tensor(sim_output_preds['sim_output'][sim_output_version_tags[version]]['valid']['pred']).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ac214-fb7e-4624-99a9-1f619879dfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sim_output_version_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba3502-b150-42da-9885-ac7427ddb406",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_sim_sim_train_cfm = confmat(sim_output_preds['sim_output'][sim_output_version_tags['version_0']]['train']['pred'], sim_output_preds['sim_output'][sim_output_version_tags['version_0']]['train']['truth'])\n",
    "pt_sim_sim_val_cfm = confmat(sim_output_preds['sim_output'][sim_output_version_tags['version_0']]['valid']['pred'], sim_output_preds['sim_output'][sim_output_version_tags['version_0']]['valid']['truth'])\n",
    "npt_sim_sim_train_cfm = confmat(sim_output_preds['sim_output'][sim_output_version_tags['version_1']]['train']['pred'], sim_output_preds['sim_output'][sim_output_version_tags['version_1']]['train']['truth'])\n",
    "npt_sim_sim_val_cfm = confmat(sim_output_preds['sim_output'][sim_output_version_tags['version_1']]['valid']['pred'], sim_output_preds['sim_output'][sim_output_version_tags['version_1']]['valid']['truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eae6684-e34c-47c0-a3c7-74d312f53856",
   "metadata": {},
   "outputs": [],
   "source": [
    "npt_sim_sim_train_cfm_df = pd.DataFrame(npt_sim_sim_train_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "npt_sim_sim_val_cfm_df = pd.DataFrame(npt_sim_sim_val_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "pt_sim_sim_train_cfm_df = pd.DataFrame(pt_sim_sim_train_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "pt_sim_sim_val_cfm_df = pd.DataFrame(pt_sim_sim_val_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dcba09-072a-4c0b-9b50-75c25de8a1f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(10,10))\n",
    "sns.heatmap(npt_sim_sim_train_cfm_df, annot=True, ax=ax[0][0], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(npt_sim_sim_val_cfm_df, annot=True, ax=ax[1][0], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(pt_sim_sim_train_cfm_df, annot=True, ax=ax[0][1], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(pt_sim_sim_val_cfm_df, annot=True, ax=ax[1][1], square=True, cbar=False, cmap='Blues')\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.set_ylabel(\"Truth\")\n",
    "    a.set_xlabel(\"Prediction\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(path_results, 'sim_sim_cfm.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c14121-347a-49b8-9f7e-4aa3aa56e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in resampled_sample_versions:\n",
    "    checkpoint_path = os.path.join(resampled_sample_folder, version, 'checkpoints', 'last.ckpt')\n",
    "    classifier = Classifier.load_from_checkpoint(checkpoint_path).cuda()\n",
    "    resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]] = {}\n",
    "    \n",
    "    resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]]['train'] = {}\n",
    "    resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]]['valid'] = {}\n",
    "\n",
    "    # Training dataset\n",
    "    resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]]['train']['pred'] = []\n",
    "    resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]]['train']['truth'] = []\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        sample, target = batch\n",
    "        \n",
    "        sample = torch.cat((sample, sample, sample), dim=1).cuda()\n",
    "        pred = classifier(sample)\n",
    "        target = torch.argmax(target, dim=-1).detach().cpu()\n",
    "        pred = torch.argmax(pred, dim=-1).cpu()\n",
    "\n",
    "        resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]]['train']['pred'].append(pred)\n",
    "        resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]]['train']['truth'].append(target)\n",
    "    # Validation dataset\n",
    "    resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]]['valid']['pred'] = []\n",
    "    resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]]['valid']['truth'] = []\n",
    "    for batch in tqdm(valid_dataloader):\n",
    "        sample, target = batch\n",
    "        \n",
    "        sample = torch.cat((sample, sample, sample), dim=1).cuda()\n",
    "        pred = classifier(sample)\n",
    "        target = torch.argmax(target, dim=-1).detach().cpu()\n",
    "        pred = torch.argmax(pred, dim=-1).cpu()\n",
    "\n",
    "        resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]]['valid']['pred'].append(pred)\n",
    "        resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]]['valid']['truth'].append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249ad78-adbc-455f-a46c-bd2fcad14e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in resampled_sample_versions:\n",
    "    resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]]['train']['pred'] = torch.tensor(resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]]['train']['pred']).squeeze()\n",
    "    resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]]['train']['truth'] = torch.tensor(resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]]['train']['truth']).squeeze()\n",
    "    resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]]['valid']['truth'] = torch.tensor(resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]]['valid']['truth']).squeeze()\n",
    "    resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]]['valid']['pred'] = torch.tensor(resampled_sample_preds['sim_output'][resampled_sample_version_tags[version]]['valid']['pred']).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca865b4-0082-4258-8ad0-36c5b01d42ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resampled_sample_version_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9b5c4-ad7c-49e7-8516-352a1f9f787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_sample_sim_train_cfm = confmat(resampled_sample_preds['sim_output'][resampled_sample_version_tags['version_0']]['train']['pred'], resampled_sample_preds['sim_output'][resampled_sample_version_tags['version_0']]['train']['truth'])\n",
    "pt_sample_sim_val_cfm = confmat(resampled_sample_preds['sim_output'][resampled_sample_version_tags['version_0']]['valid']['pred'], resampled_sample_preds['sim_output'][resampled_sample_version_tags['version_0']]['valid']['truth'])\n",
    "npt_sample_sim_train_cfm = confmat(resampled_sample_preds['sim_output'][resampled_sample_version_tags['version_1']]['train']['pred'], resampled_sample_preds['sim_output'][resampled_sample_version_tags['version_1']]['train']['truth'])\n",
    "npt_sample_sim_val_cfm = confmat(resampled_sample_preds['sim_output'][resampled_sample_version_tags['version_1']]['valid']['pred'], resampled_sample_preds['sim_output'][resampled_sample_version_tags['version_1']]['valid']['truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ba463b-e2f1-4c87-9d9c-9336788da495",
   "metadata": {},
   "outputs": [],
   "source": [
    "npt_sample_sim_train_cfm_df = pd.DataFrame(npt_sample_sim_train_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "npt_sample_sim_val_cfm_df = pd.DataFrame(npt_sample_sim_val_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "pt_sample_sim_train_cfm_df = pd.DataFrame(pt_sample_sim_train_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "pt_sample_sim_val_cfm_df = pd.DataFrame(pt_sample_sim_val_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4ccbc2-2f34-43d4-8bf9-26bd758ef20f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(10,10))\n",
    "sns.heatmap(npt_sample_sim_train_cfm_df, annot=True, ax=ax[0][0], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(npt_sample_sim_val_cfm_df, annot=True, ax=ax[1][0], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(pt_sample_sim_train_cfm_df, annot=True, ax=ax[0][1], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(pt_sample_sim_val_cfm_df, annot=True, ax=ax[1][1], square=True, cbar=False, cmap='Blues')\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.set_ylabel(\"Truth\")\n",
    "    a.set_xlabel(\"Prediction\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(path_results, 'sample_sim_cfm.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3594cf-a00d-4181-b0cf-76cbf7422409",
   "metadata": {},
   "source": [
    "## Ideal images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6b3436-f631-40d6-a2b1-1bec8af857d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_image_preds['resampled_sample'] = {}\n",
    "sim_output_preds['resampled_sample'] = {}\n",
    "resampled_sample_preds['resampled_sample'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4716b58f-382f-4f43-a49a-c625c9369da0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config['which_data'] = 'resampled_sample'\n",
    "dm = select_data(config)\n",
    "dm.setup()\n",
    "train_dataloader = dm.train_dataloader()\n",
    "valid_dataloader = dm.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c822517f-1ae8-4bd5-bc24-3308a66454da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for version in bench_image_versions:\n",
    "    checkpoint_path = os.path.join(bench_image_folder, version, 'checkpoints', 'last.ckpt')\n",
    "    classifier = Classifier.load_from_checkpoint(checkpoint_path).cuda()\n",
    "    bench_image_preds['resampled_sample'][bench_image_version_tags[version]] = {}\n",
    "    \n",
    "    bench_image_preds['resampled_sample'][bench_image_version_tags[version]]['train'] = {}\n",
    "    bench_image_preds['resampled_sample'][bench_image_version_tags[version]]['valid'] = {}\n",
    "\n",
    "    # Training dataset\n",
    "    bench_image_preds['resampled_sample'][bench_image_version_tags[version]]['train']['pred'] = []\n",
    "    bench_image_preds['resampled_sample'][bench_image_version_tags[version]]['train']['truth'] = []\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        sample, target = batch\n",
    "        \n",
    "        sample = torch.cat((sample, sample, sample), dim=1).cuda()\n",
    "        pred = classifier(sample)\n",
    "        target = torch.argmax(target, dim=-1).detach().cpu()\n",
    "        pred = torch.argmax(pred, dim=-1).cpu()\n",
    "\n",
    "        bench_image_preds['resampled_sample'][bench_image_version_tags[version]]['train']['pred'].append(pred)\n",
    "        bench_image_preds['resampled_sample'][bench_image_version_tags[version]]['train']['truth'].append(target)\n",
    "    # Validation dataset\n",
    "    bench_image_preds['resampled_sample'][bench_image_version_tags[version]]['valid']['pred'] = []\n",
    "    bench_image_preds['resampled_sample'][bench_image_version_tags[version]]['valid']['truth'] = []\n",
    "    for batch in tqdm(valid_dataloader):\n",
    "        sample, target = batch\n",
    "        \n",
    "        sample = torch.cat((sample, sample, sample), dim=1).cuda()\n",
    "        pred = classifier(sample)\n",
    "        target = torch.argmax(target, dim=-1).detach().cpu()\n",
    "        pred = torch.argmax(pred, dim=-1).cpu()\n",
    "\n",
    "        bench_image_preds['resampled_sample'][bench_image_version_tags[version]]['valid']['pred'].append(pred)\n",
    "        bench_image_preds['resampled_sample'][bench_image_version_tags[version]]['valid']['truth'].append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ae2d5c-69ed-46bd-90f7-959f87245504",
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in bench_image_versions:\n",
    "    bench_image_preds['resampled_sample'][bench_image_version_tags[version]]['train']['pred'] = torch.tensor(bench_image_preds['resampled_sample'][bench_image_version_tags[version]]['train']['pred']).squeeze()\n",
    "    bench_image_preds['resampled_sample'][bench_image_version_tags[version]]['train']['truth'] = torch.tensor(bench_image_preds['resampled_sample'][bench_image_version_tags[version]]['train']['truth']).squeeze()\n",
    "    bench_image_preds['resampled_sample'][bench_image_version_tags[version]]['valid']['truth'] = torch.tensor(bench_image_preds['resampled_sample'][bench_image_version_tags[version]]['valid']['truth']).squeeze()\n",
    "    bench_image_preds['resampled_sample'][bench_image_version_tags[version]]['valid']['pred'] = torch.tensor(bench_image_preds['resampled_sample'][bench_image_version_tags[version]]['valid']['pred']).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccfada0-1888-47f3-8a7e-bdd2e182bd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "confmat = ConfusionMatrix(task=\"multiclass\", num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e17664-bfef-431c-a829-57ae368cf648",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_bench_sample_train_cfm = confmat(bench_image_preds['resampled_sample'][bench_image_version_tags['version_0']]['train']['pred'], bench_image_preds['resampled_sample'][bench_image_version_tags['version_0']]['train']['truth'])\n",
    "pt_bench_sample_val_cfm = confmat(bench_image_preds['resampled_sample'][bench_image_version_tags['version_0']]['valid']['pred'], bench_image_preds['resampled_sample'][bench_image_version_tags['version_0']]['valid']['truth'])\n",
    "npt_bench_sample_train_cfm = confmat(bench_image_preds['resampled_sample'][bench_image_version_tags['version_1']]['train']['pred'], bench_image_preds['resampled_sample'][bench_image_version_tags['version_1']]['train']['truth'])\n",
    "npt_bench_sample_val_cfm = confmat(bench_image_preds['resampled_sample'][bench_image_version_tags['version_1']]['valid']['pred'], bench_image_preds['resampled_sample'][bench_image_version_tags['version_1']]['valid']['truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b8bfe-a470-42a3-8b93-67f476c96a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "npt_bench_sample_train_cfm_df = pd.DataFrame(npt_bench_sample_train_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "npt_bench_sample_val_cfm_df = pd.DataFrame(npt_bench_sample_val_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "pt_bench_sample_train_cfm_df = pd.DataFrame(pt_bench_sample_train_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "pt_bench_sample_val_cfm_df = pd.DataFrame(pt_bench_sample_val_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6782ea4-1f63-404e-bc4c-84f6c2d6d46f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(10,10))\n",
    "sns.heatmap(npt_bench_sample_train_cfm_df, annot=True, ax=ax[0][0], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(npt_bench_sample_val_cfm_df, annot=True, ax=ax[1][0], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(pt_bench_sample_train_cfm_df, annot=True, ax=ax[0][1], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(pt_bench_sample_val_cfm_df, annot=True, ax=ax[1][1], square=True, cbar=False, cmap='Blues')\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.set_ylabel(\"Truth\")\n",
    "    a.set_xlabel(\"Prediction\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(path_results, 'bench_sample_cfm.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e87a197-01f0-4d32-81b1-5d1012ca1196",
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in sim_output_versions:\n",
    "    checkpoint_path = os.path.join(sim_output_folder, version, 'checkpoints', 'last.ckpt')\n",
    "    classifier = Classifier.load_from_checkpoint(checkpoint_path).cuda()\n",
    "    sim_output_preds['resampled_sample'][sim_output_version_tags[version]] = {}\n",
    "    \n",
    "    sim_output_preds['resampled_sample'][sim_output_version_tags[version]]['train'] = {}\n",
    "    sim_output_preds['resampled_sample'][sim_output_version_tags[version]]['valid'] = {}\n",
    "\n",
    "    # Training dataset\n",
    "    sim_output_preds['resampled_sample'][sim_output_version_tags[version]]['train']['pred'] = []\n",
    "    sim_output_preds['resampled_sample'][sim_output_version_tags[version]]['train']['truth'] = []\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        sample, target = batch\n",
    "        \n",
    "        sample = torch.cat((sample, sample, sample), dim=1).cuda()\n",
    "        pred = classifier(sample)\n",
    "        target = torch.argmax(target, dim=-1).detach().cpu()\n",
    "        pred = torch.argmax(pred, dim=-1).cpu()\n",
    "\n",
    "        sim_output_preds['resampled_sample'][sim_output_version_tags[version]]['train']['pred'].append(pred)\n",
    "        sim_output_preds['resampled_sample'][sim_output_version_tags[version]]['train']['truth'].append(target)\n",
    "    # Validation dataset\n",
    "    sim_output_preds['resampled_sample'][sim_output_version_tags[version]]['valid']['pred'] = []\n",
    "    sim_output_preds['resampled_sample'][sim_output_version_tags[version]]['valid']['truth'] = []\n",
    "    for batch in tqdm(valid_dataloader):\n",
    "        sample, target = batch\n",
    "        \n",
    "        sample = torch.cat((sample, sample, sample), dim=1).cuda()\n",
    "        pred = classifier(sample)\n",
    "        target = torch.argmax(target, dim=-1).detach().cpu()\n",
    "        pred = torch.argmax(pred, dim=-1).cpu()\n",
    "\n",
    "        sim_output_preds['resampled_sample'][sim_output_version_tags[version]]['valid']['pred'].append(pred)\n",
    "        sim_output_preds['resampled_sample'][sim_output_version_tags[version]]['valid']['truth'].append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0ed2db-a82e-43a4-8c7d-84b7c3cc003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in sim_output_versions:\n",
    "    sim_output_preds['resampled_sample'][sim_output_version_tags[version]]['train']['pred'] = torch.tensor(sim_output_preds['resampled_sample'][sim_output_version_tags[version]]['train']['pred']).squeeze()\n",
    "    sim_output_preds['resampled_sample'][sim_output_version_tags[version]]['train']['truth'] = torch.tensor(sim_output_preds['resampled_sample'][sim_output_version_tags[version]]['train']['truth']).squeeze()\n",
    "    sim_output_preds['resampled_sample'][sim_output_version_tags[version]]['valid']['truth'] = torch.tensor(sim_output_preds['resampled_sample'][sim_output_version_tags[version]]['valid']['truth']).squeeze()\n",
    "    sim_output_preds['resampled_sample'][sim_output_version_tags[version]]['valid']['pred'] = torch.tensor(sim_output_preds['resampled_sample'][sim_output_version_tags[version]]['valid']['pred']).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df5ad79-093c-4307-a385-82bffdc9f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sim_output_version_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab6031-0734-4e84-8211-b1718bcd2e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_sim_sample_train_cfm = confmat(sim_output_preds['resampled_sample'][sim_output_version_tags['version_0']]['train']['pred'], sim_output_preds['resampled_sample'][sim_output_version_tags['version_0']]['train']['truth'])\n",
    "pt_sim_sample_val_cfm = confmat(sim_output_preds['resampled_sample'][sim_output_version_tags['version_0']]['valid']['pred'], sim_output_preds['resampled_sample'][sim_output_version_tags['version_0']]['valid']['truth'])\n",
    "npt_sim_sample_train_cfm = confmat(sim_output_preds['resampled_sample'][sim_output_version_tags['version_1']]['train']['pred'], sim_output_preds['resampled_sample'][sim_output_version_tags['version_1']]['train']['truth'])\n",
    "npt_sim_sample_val_cfm = confmat(sim_output_preds['resampled_sample'][sim_output_version_tags['version_1']]['valid']['pred'], sim_output_preds['resampled_sample'][sim_output_version_tags['version_1']]['valid']['truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99495e5-7138-43d0-b867-0dbe0c3b5789",
   "metadata": {},
   "outputs": [],
   "source": [
    "npt_sim_sample_train_cfm_df = pd.DataFrame(npt_sim_sample_train_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "npt_sim_sample_val_cfm_df = pd.DataFrame(npt_sim_sample_val_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "pt_sim_sample_train_cfm_df = pd.DataFrame(pt_sim_sample_train_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "pt_sim_sample_val_cfm_df = pd.DataFrame(pt_sim_sample_val_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b350d-c07e-43ac-9d64-3dc85f52dc9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(10,10))\n",
    "sns.heatmap(npt_sim_sample_train_cfm_df, annot=True, ax=ax[0][0], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(npt_sim_sample_val_cfm_df, annot=True, ax=ax[1][0], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(pt_sim_sample_train_cfm_df, annot=True, ax=ax[0][1], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(pt_sim_sample_val_cfm_df, annot=True, ax=ax[1][1], square=True, cbar=False, cmap='Blues')\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.set_ylabel(\"Truth\")\n",
    "    a.set_xlabel(\"Prediction\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(path_results, 'sim_sample_cfm.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c26c44a-0a26-46f5-9ccd-d8eb403e8c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in resampled_sample_versions:\n",
    "    checkpoint_path = os.path.join(resampled_sample_folder, version, 'checkpoints', 'last.ckpt')\n",
    "    classifier = Classifier.load_from_checkpoint(checkpoint_path).cuda()\n",
    "    resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]] = {}\n",
    "    \n",
    "    resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]]['train'] = {}\n",
    "    resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]]['valid'] = {}\n",
    "\n",
    "    # Training dataset\n",
    "    resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]]['train']['pred'] = []\n",
    "    resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]]['train']['truth'] = []\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        sample, target = batch\n",
    "        \n",
    "        sample = torch.cat((sample, sample, sample), dim=1).cuda()\n",
    "        pred = classifier(sample)\n",
    "        target = torch.argmax(target, dim=-1).detach().cpu()\n",
    "        pred = torch.argmax(pred, dim=-1).cpu()\n",
    "\n",
    "        resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]]['train']['pred'].append(pred)\n",
    "        resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]]['train']['truth'].append(target)\n",
    "    # Validation dataset\n",
    "    resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]]['valid']['pred'] = []\n",
    "    resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]]['valid']['truth'] = []\n",
    "    for batch in tqdm(valid_dataloader):\n",
    "        sample, target = batch\n",
    "        \n",
    "        sample = torch.cat((sample, sample, sample), dim=1).cuda()\n",
    "        pred = classifier(sample)\n",
    "        target = torch.argmax(target, dim=-1).detach().cpu()\n",
    "        pred = torch.argmax(pred, dim=-1).cpu()\n",
    "\n",
    "        resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]]['valid']['pred'].append(pred)\n",
    "        resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]]['valid']['truth'].append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89035834-e0a1-462c-9735-27e335aef898",
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in resampled_sample_versions:\n",
    "    resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]]['train']['pred'] = torch.tensor(resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]]['train']['pred']).squeeze()\n",
    "    resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]]['train']['truth'] = torch.tensor(resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]]['train']['truth']).squeeze()\n",
    "    resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]]['valid']['truth'] = torch.tensor(resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]]['valid']['truth']).squeeze()\n",
    "    resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]]['valid']['pred'] = torch.tensor(resampled_sample_preds['resampled_sample'][resampled_sample_version_tags[version]]['valid']['pred']).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca7cd5-8278-4b24-9d53-b4d084a43ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resampled_sample_version_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3705646d-4ffd-46d2-b9ba-4d19648542b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_sample_sample_train_cfm = confmat(resampled_sample_preds['resampled_sample'][resampled_sample_version_tags['version_0']]['train']['pred'], resampled_sample_preds['resampled_sample'][resampled_sample_version_tags['version_0']]['train']['truth'])\n",
    "pt_sample_sample_val_cfm = confmat(resampled_sample_preds['resampled_sample'][resampled_sample_version_tags['version_0']]['valid']['pred'], resampled_sample_preds['resampled_sample'][resampled_sample_version_tags['version_0']]['valid']['truth'])\n",
    "npt_sample_sample_train_cfm = confmat(resampled_sample_preds['resampled_sample'][resampled_sample_version_tags['version_1']]['train']['pred'], resampled_sample_preds['resampled_sample'][resampled_sample_version_tags['version_1']]['train']['truth'])\n",
    "npt_sample_sample_val_cfm = confmat(resampled_sample_preds['resampled_sample'][resampled_sample_version_tags['version_1']]['valid']['pred'], resampled_sample_preds['resampled_sample'][resampled_sample_version_tags['version_1']]['valid']['truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d10b02-a756-44f1-8f5d-04f30368a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "npt_sample_sample_train_cfm_df = pd.DataFrame(npt_sample_sample_train_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "npt_sample_sample_val_cfm_df = pd.DataFrame(npt_sample_sample_val_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "pt_sample_sample_train_cfm_df = pd.DataFrame(pt_sample_sample_train_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "pt_sample_sample_val_cfm_df = pd.DataFrame(pt_sample_sample_val_cfm, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543962e-19d4-47de-9c56-3b53235fce25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(10,10))\n",
    "sns.heatmap(npt_sample_sample_train_cfm_df, annot=True, ax=ax[0][0], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(npt_sample_sample_val_cfm_df, annot=True, ax=ax[1][0], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(pt_sample_sample_train_cfm_df, annot=True, ax=ax[0][1], square=True, cbar=False, cmap='Blues')\n",
    "sns.heatmap(pt_sample_sample_val_cfm_df, annot=True, ax=ax[1][1], square=True, cbar=False, cmap='Blues')\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.set_ylabel(\"Truth\")\n",
    "    a.set_xlabel(\"Prediction\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(path_results, 'sample_sample_cfm.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f0e828-a868-4700-aa99-97fc169c6d5a",
   "metadata": {},
   "source": [
    "## Classification scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a20fe7f-d19c-43bc-ade3-477a82dadae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = F1Score(task='multiclass', num_classes=10)\n",
    "acc = Accuracy(task='multiclass', num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276e4a19-5c76-4530-bade-64d53d0e4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bench model\n",
    "# Bench data\n",
    "bench_bench_npt_train_f1 = f1(bench_image_preds['bench_image']['non-pretrained']['train']['pred'], bench_image_preds['bench_image']['non-pretrained']['train']['truth'])\n",
    "bench_bench_npt_train_acc = acc(bench_image_preds['bench_image']['non-pretrained']['train']['pred'], bench_image_preds['bench_image']['non-pretrained']['train']['truth'])\n",
    "\n",
    "bench_bench_pt_train_f1 = f1(bench_image_preds['bench_image']['pretrained']['train']['pred'], bench_image_preds['bench_image']['pretrained']['train']['truth'])\n",
    "bench_bench_pt_train_acc = acc(bench_image_preds['bench_image']['pretrained']['train']['pred'], bench_image_preds['bench_image']['pretrained']['train']['truth'])\n",
    "\n",
    "bench_bench_npt_valid_f1 = f1(bench_image_preds['bench_image']['non-pretrained']['valid']['pred'], bench_image_preds['bench_image']['non-pretrained']['valid']['truth'])\n",
    "bench_bench_npt_valid_acc = acc(bench_image_preds['bench_image']['non-pretrained']['valid']['pred'], bench_image_preds['bench_image']['non-pretrained']['valid']['truth'])\n",
    "\n",
    "bench_bench_pt_valid_f1 = f1(bench_image_preds['bench_image']['pretrained']['valid']['pred'], bench_image_preds['bench_image']['pretrained']['valid']['truth'])\n",
    "bench_bench_pt_valid_acc = acc(bench_image_preds['bench_image']['pretrained']['valid']['pred'], bench_image_preds['bench_image']['pretrained']['valid']['truth'])\n",
    "\n",
    "# Sim data\n",
    "bench_sim_npt_train_f1 = f1(bench_image_preds['sim_output']['non-pretrained']['train']['pred'], bench_image_preds['sim_output']['non-pretrained']['train']['truth'])\n",
    "bench_sim_npt_train_acc = acc(bench_image_preds['sim_output']['non-pretrained']['train']['pred'], bench_image_preds['sim_output']['non-pretrained']['train']['truth'])\n",
    "\n",
    "bench_sim_pt_train_f1 = f1(bench_image_preds['sim_output']['pretrained']['train']['pred'], bench_image_preds['sim_output']['pretrained']['train']['truth'])\n",
    "bench_sim_pt_train_acc = acc(bench_image_preds['sim_output']['pretrained']['train']['pred'], bench_image_preds['sim_output']['pretrained']['train']['truth'])\n",
    "\n",
    "bench_sim_npt_valid_f1 = f1(bench_image_preds['sim_output']['non-pretrained']['valid']['pred'], bench_image_preds['sim_output']['non-pretrained']['valid']['truth'])\n",
    "bench_sim_npt_valid_acc = acc(bench_image_preds['sim_output']['non-pretrained']['valid']['pred'], bench_image_preds['sim_output']['non-pretrained']['valid']['truth'])\n",
    "\n",
    "bench_sim_pt_valid_f1 = f1(bench_image_preds['sim_output']['pretrained']['valid']['pred'], bench_image_preds['sim_output']['pretrained']['valid']['truth'])\n",
    "bench_sim_pt_valid_acc = acc(bench_image_preds['sim_output']['pretrained']['valid']['pred'], bench_image_preds['sim_output']['pretrained']['valid']['truth'])\n",
    "\n",
    "# Sample data\n",
    "bench_sample_npt_train_f1 = f1(bench_image_preds['resampled_sample']['non-pretrained']['train']['pred'], bench_image_preds['resampled_sample']['non-pretrained']['train']['truth'])\n",
    "bench_sample_npt_train_acc = acc(bench_image_preds['resampled_sample']['non-pretrained']['train']['pred'], bench_image_preds['resampled_sample']['non-pretrained']['train']['truth'])\n",
    "\n",
    "bench_sample_pt_train_f1 = f1(bench_image_preds['resampled_sample']['pretrained']['train']['pred'], bench_image_preds['resampled_sample']['pretrained']['train']['truth'])\n",
    "bench_sample_pt_train_acc = acc(bench_image_preds['resampled_sample']['pretrained']['train']['pred'], bench_image_preds['resampled_sample']['pretrained']['train']['truth'])\n",
    "\n",
    "bench_sample_npt_valid_f1 = f1(bench_image_preds['resampled_sample']['non-pretrained']['valid']['pred'], bench_image_preds['resampled_sample']['non-pretrained']['valid']['truth'])\n",
    "bench_sample_npt_valid_acc = acc(bench_image_preds['resampled_sample']['non-pretrained']['valid']['pred'], bench_image_preds['resampled_sample']['non-pretrained']['valid']['truth'])\n",
    "\n",
    "bench_sample_pt_valid_f1 = f1(bench_image_preds['resampled_sample']['pretrained']['valid']['pred'], bench_image_preds['resampled_sample']['pretrained']['valid']['truth'])\n",
    "bench_sample_pt_valid_acc = acc(bench_image_preds['resampled_sample']['pretrained']['valid']['pred'], bench_image_preds['resampled_sample']['pretrained']['valid']['truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63828661-e49b-4132-bca4-3b9a8f668de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample model\n",
    "# Bench data\n",
    "sample_bench_npt_train_f1 = f1(resampled_sample_preds['bench_image']['non-pretrained']['train']['pred'], resampled_sample_preds['bench_image']['non-pretrained']['train']['truth'])\n",
    "sample_bench_npt_train_acc = acc(resampled_sample_preds['bench_image']['non-pretrained']['train']['pred'], resampled_sample_preds['bench_image']['non-pretrained']['train']['truth'])\n",
    "\n",
    "sample_bench_pt_train_f1 = f1(resampled_sample_preds['bench_image']['pretrained']['train']['pred'], resampled_sample_preds['bench_image']['pretrained']['train']['truth'])\n",
    "sample_bench_pt_train_acc = acc(resampled_sample_preds['bench_image']['pretrained']['train']['pred'], resampled_sample_preds['bench_image']['pretrained']['train']['truth'])\n",
    "\n",
    "sample_bench_npt_valid_f1 = f1(resampled_sample_preds['bench_image']['non-pretrained']['valid']['pred'], resampled_sample_preds['bench_image']['non-pretrained']['valid']['truth'])\n",
    "sample_bench_npt_valid_acc = acc(resampled_sample_preds['bench_image']['non-pretrained']['valid']['pred'], resampled_sample_preds['bench_image']['non-pretrained']['valid']['truth'])\n",
    "\n",
    "sample_bench_pt_valid_f1 = f1(resampled_sample_preds['bench_image']['pretrained']['valid']['pred'], resampled_sample_preds['bench_image']['pretrained']['valid']['truth'])\n",
    "sample_bench_pt_valid_acc = acc(resampled_sample_preds['bench_image']['pretrained']['valid']['pred'], resampled_sample_preds['bench_image']['pretrained']['valid']['truth'])\n",
    "\n",
    "# Sim data\n",
    "sample_sim_npt_train_f1 = f1(resampled_sample_preds['sim_output']['non-pretrained']['train']['pred'], resampled_sample_preds['sim_output']['non-pretrained']['train']['truth'])\n",
    "sample_sim_npt_train_acc = acc(resampled_sample_preds['sim_output']['non-pretrained']['train']['pred'], resampled_sample_preds['sim_output']['non-pretrained']['train']['truth'])\n",
    "\n",
    "sample_sim_pt_train_f1 = f1(resampled_sample_preds['sim_output']['pretrained']['train']['pred'], resampled_sample_preds['sim_output']['pretrained']['train']['truth'])\n",
    "sample_sim_pt_train_acc = acc(resampled_sample_preds['sim_output']['pretrained']['train']['pred'], resampled_sample_preds['sim_output']['pretrained']['train']['truth'])\n",
    "\n",
    "sample_sim_npt_valid_f1 = f1(resampled_sample_preds['sim_output']['non-pretrained']['valid']['pred'], resampled_sample_preds['sim_output']['non-pretrained']['valid']['truth'])\n",
    "sample_sim_npt_valid_acc = acc(resampled_sample_preds['sim_output']['non-pretrained']['valid']['pred'], resampled_sample_preds['sim_output']['non-pretrained']['valid']['truth'])\n",
    "\n",
    "sample_sim_pt_valid_f1 = f1(resampled_sample_preds['sim_output']['pretrained']['valid']['pred'], resampled_sample_preds['sim_output']['pretrained']['valid']['truth'])\n",
    "sample_sim_pt_valid_acc = acc(resampled_sample_preds['sim_output']['pretrained']['valid']['pred'], resampled_sample_preds['sim_output']['pretrained']['valid']['truth'])\n",
    "\n",
    "# Sample data\n",
    "sample_sample_npt_train_f1 = f1(resampled_sample_preds['resampled_sample']['non-pretrained']['train']['pred'], resampled_sample_preds['resampled_sample']['non-pretrained']['train']['truth'])\n",
    "sample_sample_npt_train_acc = acc(resampled_sample_preds['resampled_sample']['non-pretrained']['train']['pred'], resampled_sample_preds['resampled_sample']['non-pretrained']['train']['truth'])\n",
    "\n",
    "sample_sample_pt_train_f1 = f1(resampled_sample_preds['resampled_sample']['pretrained']['train']['pred'], resampled_sample_preds['resampled_sample']['pretrained']['train']['truth'])\n",
    "sample_sample_pt_train_acc = acc(resampled_sample_preds['resampled_sample']['pretrained']['train']['pred'], resampled_sample_preds['resampled_sample']['pretrained']['train']['truth'])\n",
    "\n",
    "sample_sample_npt_valid_f1 = f1(resampled_sample_preds['resampled_sample']['non-pretrained']['valid']['pred'], resampled_sample_preds['resampled_sample']['non-pretrained']['valid']['truth'])\n",
    "sample_sample_npt_valid_acc = acc(resampled_sample_preds['resampled_sample']['non-pretrained']['valid']['pred'], resampled_sample_preds['resampled_sample']['non-pretrained']['valid']['truth'])\n",
    "\n",
    "sample_sample_pt_valid_f1 = f1(resampled_sample_preds['resampled_sample']['pretrained']['valid']['pred'], resampled_sample_preds['resampled_sample']['pretrained']['valid']['truth'])\n",
    "sample_sample_pt_valid_acc = acc(resampled_sample_preds['resampled_sample']['pretrained']['valid']['pred'], resampled_sample_preds['resampled_sample']['pretrained']['valid']['truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdcfa41-2913-4633-a3f3-a898a6304fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim model\n",
    "# Bench data\n",
    "sim_bench_npt_train_f1 = f1(sim_output_preds['bench_image']['non-pretrained']['train']['pred'], sim_output_preds['bench_image']['non-pretrained']['train']['truth'])\n",
    "sim_bench_npt_train_acc = acc(sim_output_preds['bench_image']['non-pretrained']['train']['pred'], sim_output_preds['bench_image']['non-pretrained']['train']['truth'])\n",
    "\n",
    "sim_bench_pt_train_f1 = f1(sim_output_preds['bench_image']['pretrained']['train']['pred'], sim_output_preds['bench_image']['pretrained']['train']['truth'])\n",
    "sim_bench_pt_train_acc = acc(sim_output_preds['bench_image']['pretrained']['train']['pred'], sim_output_preds['bench_image']['pretrained']['train']['truth'])\n",
    "\n",
    "sim_bench_npt_valid_f1 = f1(sim_output_preds['bench_image']['non-pretrained']['valid']['pred'], sim_output_preds['bench_image']['non-pretrained']['valid']['truth'])\n",
    "sim_bench_npt_valid_acc = acc(sim_output_preds['bench_image']['non-pretrained']['valid']['pred'], sim_output_preds['bench_image']['non-pretrained']['valid']['truth'])\n",
    "\n",
    "sim_bench_pt_valid_f1 = f1(sim_output_preds['bench_image']['pretrained']['valid']['pred'], sim_output_preds['bench_image']['pretrained']['valid']['truth'])\n",
    "sim_bench_pt_valid_acc = acc(sim_output_preds['bench_image']['pretrained']['valid']['pred'], sim_output_preds['bench_image']['pretrained']['valid']['truth'])\n",
    "\n",
    "# Sim data\n",
    "sim_sim_npt_train_f1 = f1(sim_output_preds['sim_output']['non-pretrained']['train']['pred'], sim_output_preds['sim_output']['non-pretrained']['train']['truth'])\n",
    "sim_sim_npt_train_acc = acc(sim_output_preds['sim_output']['non-pretrained']['train']['pred'], sim_output_preds['sim_output']['non-pretrained']['train']['truth'])\n",
    "\n",
    "sim_sim_pt_train_f1 = f1(sim_output_preds['sim_output']['pretrained']['train']['pred'], sim_output_preds['sim_output']['pretrained']['train']['truth'])\n",
    "sim_sim_pt_train_acc = acc(sim_output_preds['sim_output']['pretrained']['train']['pred'], sim_output_preds['sim_output']['pretrained']['train']['truth'])\n",
    "\n",
    "sim_sim_npt_valid_f1 = f1(sim_output_preds['sim_output']['non-pretrained']['valid']['pred'], sim_output_preds['sim_output']['non-pretrained']['valid']['truth'])\n",
    "sim_sim_npt_valid_acc = acc(sim_output_preds['sim_output']['non-pretrained']['valid']['pred'], sim_output_preds['sim_output']['non-pretrained']['valid']['truth'])\n",
    "\n",
    "sim_sim_pt_valid_f1 = f1(sim_output_preds['sim_output']['pretrained']['valid']['pred'], sim_output_preds['sim_output']['pretrained']['valid']['truth'])\n",
    "sim_sim_pt_valid_acc = acc(sim_output_preds['sim_output']['pretrained']['valid']['pred'], sim_output_preds['sim_output']['pretrained']['valid']['truth'])\n",
    "\n",
    "# Sample data\n",
    "sim_sample_npt_train_f1 = f1(sim_output_preds['resampled_sample']['non-pretrained']['train']['pred'], sim_output_preds['resampled_sample']['non-pretrained']['train']['truth'])\n",
    "sim_sample_npt_train_acc = acc(sim_output_preds['resampled_sample']['non-pretrained']['train']['pred'], sim_output_preds['resampled_sample']['non-pretrained']['train']['truth'])\n",
    "\n",
    "sim_sample_pt_train_f1 = f1(sim_output_preds['resampled_sample']['pretrained']['train']['pred'], sim_output_preds['resampled_sample']['pretrained']['train']['truth'])\n",
    "sim_sample_pt_train_acc = acc(sim_output_preds['resampled_sample']['pretrained']['train']['pred'], sim_output_preds['resampled_sample']['pretrained']['train']['truth'])\n",
    "\n",
    "sim_sample_npt_valid_f1 = f1(sim_output_preds['resampled_sample']['non-pretrained']['valid']['pred'], sim_output_preds['resampled_sample']['non-pretrained']['valid']['truth'])\n",
    "sim_sample_npt_valid_acc = acc(sim_output_preds['resampled_sample']['non-pretrained']['valid']['pred'], sim_output_preds['resampled_sample']['non-pretrained']['valid']['truth'])\n",
    "\n",
    "sim_sample_pt_valid_f1 = f1(sim_output_preds['resampled_sample']['pretrained']['valid']['pred'], sim_output_preds['resampled_sample']['pretrained']['valid']['truth'])\n",
    "sim_sample_pt_valid_acc = acc(sim_output_preds['resampled_sample']['pretrained']['valid']['pred'], sim_output_preds['resampled_sample']['pretrained']['valid']['truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c350d-df9f-4f64-aa10-122587c6db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data f1 table npt\n",
    "f1row0 = [sample_sample_npt_train_f1, sim_sample_npt_train_f1, bench_sample_npt_train_f1]\n",
    "f1row1 = [sample_sim_npt_train_f1, sim_sim_npt_train_f1, bench_sim_npt_train_f1]\n",
    "f1row2 = [sample_bench_npt_train_f1, sim_bench_npt_train_f1, bench_bench_npt_train_f1]\n",
    "\n",
    "# Training data f1 table pt\n",
    "f1row3 = [sample_sample_pt_train_f1, sim_sample_pt_train_f1, bench_sample_pt_train_f1]\n",
    "f1row4 = [sample_sim_pt_train_f1, sim_sim_pt_train_f1, bench_sim_pt_train_f1]\n",
    "f1row5 = [sample_bench_pt_train_f1, sim_bench_pt_train_f1, bench_bench_pt_train_f1]\n",
    "\n",
    "# Validation data f1 table npt\n",
    "f1row6 = [sample_sample_npt_valid_f1, sim_sample_npt_valid_f1, bench_sample_npt_valid_f1]\n",
    "f1row7 = [sample_sim_npt_valid_f1, sim_sim_npt_valid_f1, bench_sim_npt_valid_f1]\n",
    "f1row8 = [sample_bench_npt_valid_f1, sim_bench_npt_valid_f1, bench_bench_npt_valid_f1]\n",
    "\n",
    "# Validation data f1 table pt\n",
    "f1row9 = [sample_sample_pt_valid_f1, sim_sample_pt_valid_f1, bench_sample_pt_valid_f1]\n",
    "f1row10 = [sample_sim_pt_valid_f1, sim_sim_pt_valid_f1, bench_sim_pt_valid_f1]\n",
    "f1row11 = [sample_bench_pt_valid_f1, sim_bench_pt_valid_f1, bench_bench_pt_valid_f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5050b84a-a8cf-4cee-9d44-ced15072096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data acc table npt\n",
    "accrow0 = [sample_sample_npt_train_acc, sim_sample_npt_train_acc, bench_sample_npt_train_acc]\n",
    "accrow1 = [sample_sim_npt_train_acc, sim_sim_npt_train_acc, bench_sim_npt_train_acc]\n",
    "accrow2 = [sample_bench_npt_train_acc, sim_bench_npt_train_acc, bench_bench_npt_train_acc]\n",
    "\n",
    "# Training data acc table pt\n",
    "accrow3 = [sample_sample_pt_train_acc, sim_sample_pt_train_acc, bench_sample_pt_train_acc]\n",
    "accrow4 = [sample_sim_pt_train_acc, sim_sim_pt_train_acc, bench_sim_pt_train_acc]\n",
    "accrow5 = [sample_bench_pt_train_acc, sim_bench_pt_train_acc, bench_bench_pt_train_acc]\n",
    "\n",
    "# Validation data acc table npt\n",
    "accrow6 = [sample_sample_npt_valid_acc, sim_sample_npt_valid_acc, bench_sample_npt_valid_acc]\n",
    "accrow7 = [sample_sim_npt_valid_acc, sim_sim_npt_valid_acc, bench_sim_npt_valid_acc]\n",
    "accrow8 = [sample_bench_npt_valid_acc, sim_bench_npt_valid_acc, bench_bench_npt_valid_acc]\n",
    "\n",
    "# Validation data acc table pt\n",
    "accrow9 = [sample_sample_pt_valid_acc, sim_sample_pt_valid_acc, bench_sample_pt_valid_acc]\n",
    "accrow10 = [sample_sim_pt_valid_acc, sim_sim_pt_valid_acc, bench_sim_pt_valid_acc]\n",
    "accrow11 = [sample_bench_pt_valid_acc, sim_bench_pt_valid_acc, bench_bench_pt_valid_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8c83c-6815-4b89-8ef8-c147904f5b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "row0 = np.concatenate([f1row3, f1row0])\n",
    "row1 = np.concatenate([f1row4, f1row1])\n",
    "row2 = np.concatenate([f1row5, f1row2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ac709-df8a-41d9-b2ce-dda30c83fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(row0)\n",
    "print(row1)\n",
    "print(row2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aeaa02-8b66-446c-abd1-677f26063f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "row3 = np.concatenate([f1row9, f1row6])\n",
    "row4 = np.concatenate([f1row10, f1row7])\n",
    "row5 = np.concatenate([f1row11, f1row8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4db6aa-6157-4399-acdd-7053dd61941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(row3)\n",
    "print(row4)\n",
    "print(row5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cbf3b3-c850-4f23-87c8-f4293826bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "row6 = np.concatenate([accrow3, accrow0])\n",
    "row7 = np.concatenate([accrow4, accrow1])\n",
    "row8 = np.concatenate([accrow5, accrow2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d261d82-88e4-41df-9c14-9a3211fe77e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(row6)\n",
    "print(row7)\n",
    "print(row8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054c0513-90a4-46d9-8855-013e846a13a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "row9 = np.concatenate([accrow9, accrow6])\n",
    "row10 = np.concatenate([accrow10, accrow7])\n",
    "row11 = np.concatenate([accrow11, accrow8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4557a3-bf41-4ab5-9b74-a91ded5ecc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(row9)\n",
    "print(row10)\n",
    "print(row11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a213d2a-e3c8-46bf-a471-43d04442b15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caf5198-2800-44eb-a91a-0335af9a4098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
